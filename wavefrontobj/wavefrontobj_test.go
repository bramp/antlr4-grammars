// Copyright 2017 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Package wavefrontobj_test contains tests for the WavefrontOBJ grammar.
// The tests should be run with the -timeout flag, to ensure the parser doesn't
// get stuck.
//
// Do not edit this file, it is generated by make.go
//
package wavefrontobj_test

import (
	"bramp.net/antlr4/internal"
	"bramp.net/antlr4/wavefrontobj"

	"fmt"
	"github.com/antlr/antlr4/runtime/Go/antlr"
	"path/filepath"
	"testing"
)

const MAX_TOKENS = 1000000

var examples = []string{
	"grammars-v4/wavefront/examples/b1_14_bezier_in_u_direction_with_b_spline_in_v_direction_with_basis_matrix.txt",
	"grammars-v4/wavefront/examples/b1_14_cubic_bezier_surface_with_basis_matrix.txt",
	"grammars-v4/wavefront/examples/b1_14_hermite_curve_with_basis_matrix.txt",
	"grammars-v4/wavefront/examples/b1_20_cube.txt",
	"grammars-v4/wavefront/examples/b1_20_square.txt",
	"grammars-v4/wavefront/examples/b1_21_cube_with_negative_reference_numbers.txt",
	"grammars-v4/wavefront/examples/b1_27_taylor_curve.txt",
	"grammars-v4/wavefront/examples/b1_28_bezier_curve.txt",
	"grammars-v4/wavefront/examples/b1_29_b_spline_surface.txt",
	"grammars-v4/wavefront/examples/b1_30_cardinal_surface.txt",
	"grammars-v4/wavefront/examples/b1_31_rational_b_spline_surface.txt",
	"grammars-v4/wavefront/examples/b1_32_trimmed_nurb_surface.txt",
	"grammars-v4/wavefront/examples/b1_33_two_trimming_regions_with_hole.txt",
	"grammars-v4/wavefront/examples/b1_35_trimming_with_special_curve.txt",
	"grammars-v4/wavefront/examples/b1_36_trimming_with_special_points.txt",
	"grammars-v4/wavefront/examples/b1_39_connectivity_between_two_surfaces.txt",
	"grammars-v4/wavefront/examples/b1_43_cube_with_group_names.txt",
	"grammars-v4/wavefront/examples/b1_44_two_adjoining_squares_with_smoothing_group.txt",
	"grammars-v4/wavefront/examples/b1_45_two_adjoining_squares_with_vertex_normals.txt",
	"grammars-v4/wavefront/examples/b1_46_merging_group.txt",
	"grammars-v4/wavefront/examples/b1_55_cube_with_materials.txt",
	"grammars-v4/wavefront/examples/b1_56_cube_casting_shadow.txt",
	"grammars-v4/wavefront/examples/b1_57_cube_casting_reflection.txt",
	"grammars-v4/wavefront/examples/b1_58_texture_mapped_square.txt",
	"grammars-v4/wavefront/examples/b1_59_approximation_technique_for_surface.txt",
	"grammars-v4/wavefront/examples/b1_60_approximation_technique_for_curve.txt",
	"grammars-v4/wavefront/examples/b1_76_cardinal_curve.txt",
	"grammars-v4/wavefront/examples/b1_76_cardinal_curve_old.txt",
	"grammars-v4/wavefront/examples/b1_77_bezier_patch.txt",
	"grammars-v4/wavefront/examples/b1_77_bezier_patch_old.txt",
}

type exampleListener struct {
	*wavefrontobj.BaseWavefrontOBJListener
}

func (l *exampleListener) EnterEveryRule(ctx antlr.ParserRuleContext) {
	fmt.Println(ctx.GetText())
}
func Example() {
	// Setup the input
	is := antlr.NewInputStream("...some text to parse...")

	// Create the Lexer
	lexer := wavefrontobj.NewWavefrontOBJLexer(is)
	stream := antlr.NewCommonTokenStream(lexer, antlr.TokenDefaultChannel)

	// Create the Parser
	p := wavefrontobj.NewWavefrontOBJParser(stream)
	p.BuildParseTrees = true
	p.AddErrorListener(antlr.NewDiagnosticErrorListener(true))

	// Finally walk the tree
	tree := p.Start()
	antlr.ParseTreeWalkerDefault.Walk(&exampleListener{}, tree)
}

func newCharStream(filename string) (antlr.CharStream, error) {
	var input antlr.CharStream
	input, err := antlr.NewFileStream(filepath.Join("..", filename))
	if err != nil {
		return nil, err
	}

	return input, nil
}

func TestWavefrontOBJLexer(t *testing.T) {
	for _, file := range examples {
		input, err := newCharStream(file)
		if err != nil {
			t.Errorf("Failed to open example file: %s", err)
		}

		// Create the Lexer
		lexer := wavefrontobj.NewWavefrontOBJLexer(input)

		// Try and read all tokens
		i := 0
		for ; i < MAX_TOKENS; i++ {
			tok := lexer.NextToken()
			if tok.GetTokenType() == antlr.TokenEOF {
				break
			}
		}

		// If we read too many tokens, then perhaps there is a problem with the lexer.
		if i >= MAX_TOKENS {
			t.Errorf("NewWavefrontOBJLexer(%q) read %d tokens without finding EOF", file, i)
		}
	}
}

func TestWavefrontOBJParser(t *testing.T) {
	// TODO(bramp): Run this test with and without p.BuildParseTrees

	for _, file := range examples {
		input, err := newCharStream(file)
		if err != nil {
			t.Errorf("Failed to open example file: %s", err)
		}

		// Create the Lexer
		lexer := wavefrontobj.NewWavefrontOBJLexer(input)
		stream := antlr.NewCommonTokenStream(lexer, antlr.TokenDefaultChannel)

		// Create the Parser
		p := wavefrontobj.NewWavefrontOBJParser(stream)
		p.BuildParseTrees = true
		p.AddErrorListener(internal.NewTestingErrorListener(t, file))

		// Finally test
		p.Start()

		// TODO(bramp): If there is a "file.tree", then compare the output
		// TODO(bramp): If there is a "file.errors", then check the error
	}
}
